link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
if (navia_num  %>%
html_elements('.navia') %>% html_text2() != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1))
total_data <- bind_rows(total_data, t_data)
}
}
}
View(total_data)
library(readr)
library(magrittr)
library(tidyverse)
library(htmltools)
library(rvest)
library(janitor)
# selenium proper
library(RSelenium)
# i used rvest since i search the easier way to parse this site. without docker container etc
# find brands
data_brands <- read_html("https://www.ss.com/lv/transport/cars/sell/filter/") %>%
html_elements('.category') %>% {.[1:40]}
# based data category and links to search.
check_data <- data.frame(
brand = data_brands %>% html_text2(),
link =
paste0('https://www.ss.com/',data_brands %>% html_elements('a') %>% html_attr('href'))
)
total_data <- data.frame()
# for each brand i go through pages
for (brand in c(1:nrow(check_data))) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
if (navia_num  %>%
html_elements('.navia') %>% html_text2() != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1))
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
View(total_data)
link
page_link
View(total_data)
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
if (page_num != page & page_num != "") {
break
} else {
# [1] "Infiniti"
# [1] "https://www.ss.com//lv/transport/cars/infiniti/sell/page1.html"
# Error in if (navia_num %>% html_elements(".navia") %>% html_text2() !=  :
#              argument is of length zero
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
page_num
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
if (page_num != page & ! identical(page_num,numeric(0)) ) {
break
} else {
# [1] "Infiniti"
# [1] "https://www.ss.com//lv/transport/cars/infiniti/sell/page1.html"
# Error in if (navia_num %>% html_elements(".navia") %>% html_text2() !=  :
#              argument is of length zero
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
identical(page_num,numeric(0))
identical(page_num,character(0))
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
if (page_num != page & ! identical(page_num,character(0)) ) {
break
} else {
# [1] "Infiniti"
# [1] "https://www.ss.com//lv/transport/cars/infiniti/sell/page1.html"
# Error in if (navia_num %>% html_elements(".navia") %>% html_text2() !=  :
#              argument is of length zero
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
identical(page_num,character(0))
! identical(page_num,character(0))
identical(page_num,character(0))
page_num
! identical(page_num,character(0)) | page_num != page
! identical(page_num,character(0)) || page_num != page
identical(page_num,character(0)) || page_num != page
identical(page_num,character(0)) | page_num != page
identical(page_num,character(0)) || page_num == page
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
if ( identical(page_num,character(0)) || page_num == page) {
# [1] "Infiniti"
# [1] "https://www.ss.com//lv/transport/cars/infiniti/sell/page1.html"
# Error in if (navia_num %>% html_elements(".navia") %>% html_text2() !=  :
#              argument is of length zero
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
} else {
break
}
}
}
!identical(page_num,character(0)) & page_num != page
!identical(page_num,character(0))
page_num != page
!identical(page_num,character(0)) && page_num != page
page_num
identical(page_num,character(0))
!identical(page_num,character(0)) & page_num != page
page_num != page
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
if (!identical(page_num,character(0)) && page_num != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
!identical(page_num,character(0)) & page_num != page
identical(page_num,character(0))
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
page_num <- ifelse(identical(page_num,character(0)), 0, page_num)
page_num != page
page_num != page & page_num != 0
page_num != page & page_num == 0
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
page_num <- ifelse(identical(page_num,character(0)), 0, page_num)
if (page_num != page & page_num != 0) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
page_num != page & page_num != 0
page_num <- ifelse(identical(page_num,character(0)), 1, page_num)
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
page_num <- ifelse(identical(page_num,character(0)), 1, page_num)
if (page_num != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
library(readr)
library(magrittr)
library(tidyverse)
library(rvest)
library(janitor)
# i used rvest since i search the easier way to parse this site. without docker container etc
# find brands
data_brands <- read_html("https://www.ss.com/lv/transport/cars/sell/filter/") %>%
html_elements('.category') %>% {.[1:40]}
# based data category and links to search.
check_data <- data.frame(
brand = data_brands %>% html_text2(),
link =
paste0('https://www.ss.com/',data_brands %>% html_elements('a') %>% html_attr('href'))
)
total_data <- data.frame()
# for each brand i go through pages
for (brand in 13) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
# if there only 1 page, then we set to loop only first page.
page_num <- ifelse(identical(page_num,character(0)), 1, page_num)
if (page_num != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
View(total_data)
library(readr)
library(magrittr)
library(tidyverse)
library(rvest)
library(janitor)
# i used rvest since i search the easier way to parse this site. without docker container etc
# find brands
data_brands <- read_html("https://www.ss.com/lv/transport/cars/sell/filter/") %>%
html_elements('.category') %>% {.[1:40]}
# based data category and links to search.
check_data <- data.frame(
brand = data_brands %>% html_text2(),
link =
paste0('https://www.ss.com/',data_brands %>% html_elements('a') %>% html_attr('href'))
)
total_data <- data.frame()
# for each brand i go through pages
for (brand in c(1:nrow(check_data))) {
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
# if there only 1 page, then we set to loop only first page.
page_num <- ifelse(identical(page_num,character(0)), 1, page_num)
if (page_num != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
set.seed(1)
set.seed(5)
library(readr)
library(magrittr)
library(tidyverse)
library(rvest)
library(janitor)
# i used rvest since i search the easier way to parse this site. without docker container etc
# find brands
data_brands <- read_html("https://www.ss.com/lv/transport/cars/sell/filter/") %>%
html_elements('.category') %>% {.[1:40]}
# based data category and links to search.
check_data <- data.frame(
brand = data_brands %>% html_text2(),
link =
paste0('https://www.ss.com/',data_brands %>% html_elements('a') %>% html_attr('href'))
)
total_data <- data.frame()
# for each brand i go through pages
for (brand in c(1:nrow(check_data))) {
Sys.sleep(5)
print(check_data$brand[brand])
link <- check_data$link[brand]
# randomly chosen page, if .navia class is not the same as number of page then break
for (page in c(1:100)) {
Sys.sleep(3)
page_link <- paste0(link,"page",page,".html")
print(page_link)
navia_num <- read_html(page_link)
page_num <- navia_num  %>%
html_elements('.navia') %>% html_text2()
# if there only 1 page, then we set to loop only first page.
page_num <- ifelse(identical(page_num,character(0)), 1, page_num)
if (page_num != page) {
break
} else {
t_data <- navia_num %>%
html_nodes(xpath = '//*[@id="filter_frm"]/table[2]') %>%
html_table() %>%
as.data.frame() %>%
select(c(2:8)) %>%
select(-1) %>%
row_to_names(row_number=1) %>%
slice(1:(n()-1)) %>%
mutate(brand = check_data$brand[brand])
total_data <- bind_rows(total_data, t_data)
rm(t_data)
}
}
}
View(total_data)
getwd()
stringr::str_sub(
as.character(rstudioapi::getActiveDocumentContext()$path),
end = -15
)
setwd("C:/Users/farkhild/OneDrive - TietoEVRY/Desktop/GIT/R/car_market_analysis")
getwd()
write.csv(
x = total_data,
file = "ss.csv",
fileEncoding = "UTF-8",
na = "",
row.names = FALSE
)
View(total_data)
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA)))
View(total_data_parsed)
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA,","="","."="")))
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA,","="")))
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")) %>% as.numeric(),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA,","="")) %>% as.numeric())
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")) %>% as.numeric(),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA,","="")) %>% as.numeric(),
Gads = Gads %>% as.numeric())
#make data great again
total_data_parsed <- total_data %>%
mutate(Cena = str_replace_all(Cena, c(" " = "", "€" = "", "," = "")) %>% as.numeric(),
`Nobrauk.` = str_replace_all(`Nobrauk.`, c("tūkst." = "000", " " ="", "-"= NA,","="")) %>% as.numeric(),
Gads = Gads %>% as.numeric())
write.csv(
x = total_data_parsed,
file = "ss.csv",
fileEncoding = "UTF-8",
na = "",
row.names = FALSE
)
View(total_data_parsed)
